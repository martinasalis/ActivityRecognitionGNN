{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "main.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Imports**"
      ],
      "metadata": {
        "id": "XtYPG8JRkyZN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "PyTorch Geometric"
      ],
      "metadata": {
        "id": "TnliKPs6kumz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "def format_pytorch_version(version):\n",
        "  return version.split('+')[0]\n",
        "\n",
        "TORCH_version = torch.__version__\n",
        "TORCH = format_pytorch_version(TORCH_version)\n",
        "\n",
        "def format_cuda_version(version):\n",
        "  return 'cu' + version.replace('.', '')\n",
        "\n",
        "CUDA_version = torch.version.cuda\n",
        "CUDA = format_cuda_version(CUDA_version)\n",
        "\n",
        "!pip install torch-scatter     -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install torch-sparse      -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install torch-cluster     -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install torch-spline-conv -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install torch-geometric "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N-UnhmO9ktym",
        "outputId": "542b0baa-6b1f-42c9-ff20-f86d324a3e89"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.10.0+cu111.html\n",
            "Collecting torch-scatter\n",
            "  Downloading https://data.pyg.org/whl/torch-1.10.0%2Bcu113/torch_scatter-2.0.9-cp37-cp37m-linux_x86_64.whl (7.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.9 MB 5.1 MB/s \n",
            "\u001b[?25hInstalling collected packages: torch-scatter\n",
            "Successfully installed torch-scatter-2.0.9\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.10.0+cu111.html\n",
            "Collecting torch-sparse\n",
            "  Downloading https://data.pyg.org/whl/torch-1.10.0%2Bcu113/torch_sparse-0.6.13-cp37-cp37m-linux_x86_64.whl (3.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.5 MB 5.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-sparse) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scipy->torch-sparse) (1.21.6)\n",
            "Installing collected packages: torch-sparse\n",
            "Successfully installed torch-sparse-0.6.13\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.10.0+cu111.html\n",
            "Collecting torch-cluster\n",
            "  Downloading https://data.pyg.org/whl/torch-1.10.0%2Bcu113/torch_cluster-1.6.0-cp37-cp37m-linux_x86_64.whl (2.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.5 MB 5.1 MB/s \n",
            "\u001b[?25hInstalling collected packages: torch-cluster\n",
            "Successfully installed torch-cluster-1.6.0\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.10.0+cu111.html\n",
            "Collecting torch-spline-conv\n",
            "  Downloading https://data.pyg.org/whl/torch-1.10.0%2Bcu113/torch_spline_conv-1.2.1-cp37-cp37m-linux_x86_64.whl (750 kB)\n",
            "\u001b[K     |████████████████████████████████| 750 kB 5.4 MB/s \n",
            "\u001b[?25hInstalling collected packages: torch-spline-conv\n",
            "Successfully installed torch-spline-conv-1.2.1\n",
            "Collecting torch-geometric\n",
            "  Downloading torch_geometric-2.0.4.tar.gz (407 kB)\n",
            "\u001b[K     |████████████████████████████████| 407 kB 5.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (4.64.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.21.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.4.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.23.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (3.0.8)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->torch-geometric) (2.0.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->torch-geometric) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->torch-geometric) (2022.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->torch-geometric) (1.15.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (1.24.3)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch-geometric) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch-geometric) (3.1.0)\n",
            "Building wheels for collected packages: torch-geometric\n",
            "  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-geometric: filename=torch_geometric-2.0.4-py3-none-any.whl size=616603 sha256=f4bd23d39cb5868bb051ce128a6dd39bd2c127fe5447849c58ce6790e9916d10\n",
            "  Stored in directory: /root/.cache/pip/wheels/18/a6/a4/ca18c3051fcead866fe7b85700ee2240d883562a1bc70ce421\n",
            "Successfully built torch-geometric\n",
            "Installing collected packages: torch-geometric\n",
            "Successfully installed torch-geometric-2.0.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch.nn.functional as F \n",
        "\n",
        "from torch_geometric.data import InMemoryDataset, download_url, Data\n",
        "from datetime import datetime\n",
        "from torch.nn import Linear\n",
        "from torch_geometric.nn import GCNConv, TopKPooling, global_mean_pool\n",
        "from torch_geometric.nn import global_mean_pool as gap, global_max_pool as gmp"
      ],
      "metadata": {
        "id": "Uxb0MBc5Xp-E"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Mount GDrive**"
      ],
      "metadata": {
        "id": "lfAcpP41lBZh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "wbznRcKPRrnR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6c3517f-cfc2-486c-8f1e-fe20512252a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cnvyVM3RiDuL",
        "outputId": "0afecd2f-574b-454c-d2d6-58f6b7672ea1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shell-init: error retrieving current directory: getcwd: cannot access parent directories: No such file or directory\n",
            "action_types.csv              participants_activity_anomalies.csv\n",
            "activities.csv                patients.csv\n",
            "activity_types.csv            scores.csv\n",
            "anomalies.csv                 scores_predictions.csv\n",
            "anomaly_types.csv             sensor_locations.csv\n",
            "diagnosis_predictions.csv     sensors.csv\n",
            "diagnosis_types.csv           tasks.csv\n",
            "events.csv                    task_types.csv\n",
            "overt_error_action_types.csv  trajectory_anomalies.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def task_activity_sensors(tasks, events, sensors, activities, patient):\n",
        "\n",
        "  # Seleziona i task-activity eseguiti dal paziente 'patient'\n",
        "  task_activity = tasks.query('patient == ' + patient)\n",
        "\n",
        "  # Seleziona il tempo di inizio e fine delle attività svolte dal paziente 'patient'\n",
        "  activities_patient = activities.query('patient == ' + patient)\n",
        "  start_time = activities_patient.iloc[0]['start']\n",
        "  end_time = activities_patient.iloc[len(activities_patient) - 1]['end']\n",
        "\n",
        "  # Query nel dataframe events per selezionare solo i sensori utilizzati nelle attività\n",
        "  sensors_events = events.query('patient == ' + patient + ' and time >= \"' + start_time + '\" and time <= \"' + end_time + '\"')\n",
        "\n",
        "  # Matrice risultato che contiene i dati dei nodi\n",
        "  res_node = pd.DataFrame(columns=['features'])\n",
        "  res_edge = pd.DataFrame(columns=['times']) \n",
        "\n",
        "  # Dimensione dell'array delle features\n",
        "  dim_features = len(sensors)\n",
        "\n",
        "  # Dizionario che contiene la posizione del sensore nell'array delle features\n",
        "  dict_sens = {}\n",
        "\n",
        "  for i in range(0, dim_features):\n",
        "    dict_sens[sensors.iloc[i]['sensor_id']] = i\n",
        "\n",
        "  # Indice del task-activity\n",
        "  i = 0\n",
        "\n",
        "  # Numero edge del grafo\n",
        "  num_edge = 0\n",
        "\n",
        "  # Nome del task-activity precedente\n",
        "  pair_str_prev = \"\"\n",
        "\n",
        "  # Flag per salvataggio features di nodo e arco\n",
        "  ins_upd = False\n",
        "  last_node = False\n",
        "\n",
        "  for i in range(0, len(task_activity)):\n",
        "\n",
        "    # Controlla se il task-activity attuale è l'ultimo\n",
        "    if ((i + 1) >= len(task_activity)):\n",
        "      last_node = True\n",
        "\n",
        "    # Nome del task-activity attuale\n",
        "    pair_str = str(task_activity.iloc[i]['task']) + '-' + str(task_activity.iloc[i]['activity'])\n",
        "\n",
        "    # Controlla se il task-activity attuale e quello precedente sono diversi\n",
        "    if pair_str != pair_str_prev:\n",
        "\n",
        "      # Viene salvato lo start time\n",
        "      s_time = task_activity.iloc[i]['time']\n",
        "\n",
        "      # Controlla se il task-activity attuale non è l'ultimo\n",
        "      if not last_node:\n",
        "\n",
        "        # Controlla se il task-activity attuale e quello successivo sono diversi\n",
        "        if pair_str != str(task_activity.iloc[i + 1]['task']) + '-' + str(task_activity.iloc[i + 1]['activity']):\n",
        "\n",
        "          # Viene salvato l'end time\n",
        "          e_time = task_activity.iloc[i + 1]['time']\n",
        "\n",
        "          ins_upd = True\n",
        "          pair_str_prev = pair_str\n",
        "\n",
        "        else:\n",
        "          ins_upd = False\n",
        "          pair_str_prev = pair_str\n",
        "      \n",
        "      else:\n",
        "\n",
        "        # Viene salvato l'end time\n",
        "        e_time = end_time\n",
        "\n",
        "        ins_upd = True\n",
        "        pair_str_prev = pair_str\n",
        "    \n",
        "    else:\n",
        "      # Controlla se il task-activity attuale non è l'ultimo\n",
        "      if not last_node:\n",
        "\n",
        "        # Controlla se il task-activity attuale e quello successivo sono diversi\n",
        "        if pair_str != str(task_activity.iloc[i + 1]['task']) + '-' + str(task_activity.iloc[i + 1]['activity']):\n",
        "\n",
        "          # Viene salvato l'end time\n",
        "          e_time = task_activity.iloc[i + 1]['time']\n",
        "\n",
        "          ins_upd = True\n",
        "          pair_str_prev = pair_str\n",
        "        \n",
        "        else:\n",
        "          ins_upd = False\n",
        "          pair_str_prev = pair_str\n",
        "      \n",
        "      else:\n",
        "\n",
        "        # Viene salvato l'end time\n",
        "        e_time = end_time\n",
        "\n",
        "        ins_upd = True\n",
        "        pair_str_prev = pair_str\n",
        "\n",
        "    # Controlla se start ed end time sono stati trovati\n",
        "    if ins_upd:\n",
        "\n",
        "      # Controlla se il task-activity attuale non è l'ultimo\n",
        "      if not last_node:\n",
        "\n",
        "        # Aggiorna il numero di edge del grafo\n",
        "        num_edge = num_edge + 1\n",
        "\n",
        "        # Controlla se esiste un arco per il task-activity attuale \n",
        "        if pair_str in res_edge.index:\n",
        "\n",
        "          # Aggiunge start ed end time all'arco\n",
        "          res_edge.loc[pair_str, 'times'] += [((s_time, e_time), str(task_activity.iloc[i + 1]['task']) + '-' + str(task_activity.iloc[i + 1]['activity']))]\n",
        "        \n",
        "        else:\n",
        "          # Crea un nuovo arco\n",
        "          res_edge.loc[pair_str] = [[((s_time, e_time), str(task_activity.iloc[i + 1]['task']) + '-' + str(task_activity.iloc[i + 1]['activity']))]]\n",
        "\n",
        "      # Controlla se non esiste un nodo per il task-activity attuale\n",
        "      if not pair_str in res_node.index:\n",
        "\n",
        "        # Crea un array vuoto per le fueatures del nodo\n",
        "        features_node = np.zeros(dim_features, dtype=np.int8)\n",
        "\n",
        "        # Seleziona i sensori utilizzati per il task-activity attuale\n",
        "        task_activity_sensors = sensors_events.query('time >= \"' + s_time + '\" and time <= \"' + e_time + '\"')\n",
        "\n",
        "        # Popola l'array delle features\n",
        "        for _, s in task_activity_sensors.iterrows():\n",
        "          features_node[dict_sens[s['sensor']]] = 1\n",
        "\n",
        "        # Salva nel nodo l'array delle features\n",
        "        res_node.loc[pair_str] = [features_node]\n",
        "  \n",
        "  return res_edge, res_node, num_edge"
      ],
      "metadata": {
        "id": "2fjasxwrDGzd"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sensors = pd.read_csv('drive/MyDrive/CASAS400/sensors.csv')\n",
        "events = pd.read_csv('drive/MyDrive/CASAS400/events.csv')\n",
        "tasks = pd.read_csv('drive/MyDrive/CASAS400/tasks.csv')\n",
        "activities = pd.read_csv('drive/MyDrive/CASAS400/activities.csv')\n",
        "\n",
        "patients = pd.read_csv('drive/MyDrive/CASAS400/activities.csv')['patient'].unique()\n",
        "\n",
        "dataset = []\n",
        "\n",
        "for i in range(0, len(patients)):\n",
        "\n",
        "  # Crea i dataframe con le features degli edges e dei nodi\n",
        "  edge, node, num_edge = task_activity_sensors(tasks, events, sensors, activities, str(patients[i]))\n",
        "\n",
        "  # Salva la label associata al paziente\n",
        "  label = pd.read_csv('drive/MyDrive/CASAS400/patients.csv').query('patient_id == ' + str(patients[i]))['diagnosis'].values\n",
        "\n",
        "  if len(node) > 0:\n",
        "    atr_node = np.zeros([len(node), len(node.iloc[0]['features'])])\n",
        "\n",
        "    # Converte il dataframe dei nodi in una matrice\n",
        "    for j in range(0, len(node)):\n",
        "      atr_node[j] = node.iloc[j]['features']\n",
        "\n",
        "    adj_matrix = np.empty([num_edge, 2])\n",
        "    index_adj_matrix = 0\n",
        "\n",
        "    # Crea la matrice di addiacenza dei nodi\n",
        "    for j in range(0, len(edge)):\n",
        "      for k in range(0, len(edge.iloc[j]['times'])):\n",
        "        f_node = node.index.get_loc(edge.iloc[j].name)\n",
        "        s_node = node.index.get_loc(edge.iloc[j]['times'][k][1])\n",
        "\n",
        "        adj_matrix[index_adj_matrix] = np.array([f_node, s_node])\n",
        "        index_adj_matrix = index_adj_matrix + 1\n",
        "    \n",
        "    # Salva la mtrice delle features e la matrice di addiacenza del grafo\n",
        "    dataset.append(Data(x=torch.tensor(atr_node, dtype=torch.float),\n",
        "                        edge_index=torch.tensor(adj_matrix, dtype=torch.long).t().contiguous(),\n",
        "                        y=torch.tensor(label, dtype=torch.float)))"
      ],
      "metadata": {
        "id": "cT8m3JjPkOEb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ae8f931-904d-4566-cea7-e2eec5e52ac4"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "88\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/internals/blocks.py:937: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  arr_value = np.asarray(value)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "117\n",
            "184\n",
            "13\n",
            "85\n",
            "67\n",
            "171\n",
            "132\n",
            "127\n",
            "211\n",
            "136\n",
            "111\n",
            "275\n",
            "185\n",
            "301\n",
            "194\n",
            "52\n",
            "255\n",
            "210\n",
            "228\n",
            "225\n",
            "181\n",
            "172\n",
            "280\n",
            "251\n",
            "314\n",
            "48\n",
            "18\n",
            "338\n",
            "183\n",
            "299\n",
            "286\n",
            "393\n",
            "161\n",
            "331\n",
            "139\n",
            "229\n",
            "230\n",
            "25\n",
            "325\n",
            "368\n",
            "129\n",
            "253\n",
            "14\n",
            "249\n",
            "208\n",
            "335\n",
            "108\n",
            "137\n",
            "295\n",
            "358\n",
            "55\n",
            "252\n",
            "256\n",
            "110\n",
            "138\n",
            "53\n",
            "37\n",
            "140\n",
            "30\n",
            "154\n",
            "311\n",
            "8\n",
            "147\n",
            "236\n",
            "354\n",
            "259\n",
            "182\n",
            "350\n",
            "336\n",
            "242\n",
            "366\n",
            "263\n",
            "177\n",
            "50\n",
            "270\n",
            "233\n",
            "76\n",
            "400\n",
            "205\n",
            "20\n",
            "220\n",
            "152\n",
            "54\n",
            "103\n",
            "221\n",
            "216\n",
            "279\n",
            "153\n",
            "232\n",
            "342\n",
            "273\n",
            "289\n",
            "387\n",
            "39\n",
            "105\n",
            "318\n",
            "180\n",
            "40\n",
            "238\n",
            "10\n",
            "231\n",
            "326\n",
            "33\n",
            "367\n",
            "203\n",
            "372\n",
            "142\n",
            "215\n",
            "163\n",
            "188\n",
            "170\n",
            "200\n",
            "93\n",
            "70\n",
            "371\n",
            "283\n",
            "82\n",
            "264\n",
            "167\n",
            "244\n",
            "113\n",
            "261\n",
            "35\n",
            "373\n",
            "102\n",
            "327\n",
            "312\n",
            "276\n",
            "319\n",
            "91\n",
            "186\n",
            "356\n",
            "146\n",
            "282\n",
            "394\n",
            "271\n",
            "173\n",
            "56\n",
            "81\n",
            "4\n",
            "365\n",
            "323\n",
            "83\n",
            "274\n",
            "15\n",
            "192\n",
            "191\n",
            "388\n",
            "383\n",
            "165\n",
            "164\n",
            "28\n",
            "193\n",
            "352\n",
            "386\n",
            "128\n",
            "90\n",
            "281\n",
            "202\n",
            "375\n",
            "6\n",
            "197\n",
            "363\n",
            "45\n",
            "241\n",
            "155\n",
            "267\n",
            "247\n",
            "362\n",
            "141\n",
            "115\n",
            "212\n",
            "22\n",
            "382\n",
            "47\n",
            "169\n",
            "101\n",
            "340\n",
            "99\n",
            "120\n",
            "234\n",
            "321\n",
            "41\n",
            "391\n",
            "266\n",
            "250\n",
            "243\n",
            "42\n",
            "351\n",
            "72\n",
            "222\n",
            "361\n",
            "84\n",
            "395\n",
            "175\n",
            "360\n",
            "46\n",
            "359\n",
            "376\n",
            "277\n",
            "9\n",
            "346\n",
            "378\n",
            "308\n",
            "118\n",
            "389\n",
            "143\n",
            "313\n",
            "63\n",
            "145\n",
            "310\n",
            "223\n",
            "133\n",
            "130\n",
            "158\n",
            "38\n",
            "79\n",
            "107\n",
            "349\n",
            "237\n",
            "214\n",
            "71\n",
            "59\n",
            "29\n",
            "330\n",
            "293\n",
            "339\n",
            "100\n",
            "69\n",
            "58\n",
            "341\n",
            "174\n",
            "294\n",
            "106\n",
            "305\n",
            "51\n",
            "95\n",
            "268\n",
            "298\n",
            "399\n",
            "297\n",
            "77\n",
            "290\n",
            "24\n",
            "309\n",
            "392\n",
            "121\n",
            "254\n",
            "5\n",
            "149\n",
            "347\n",
            "144\n",
            "26\n",
            "98\n",
            "337\n",
            "306\n",
            "134\n",
            "248\n",
            "80\n",
            "32\n",
            "317\n",
            "112\n",
            "87\n",
            "384\n",
            "304\n",
            "11\n",
            "348\n",
            "334\n",
            "201\n",
            "122\n",
            "396\n",
            "97\n",
            "157\n",
            "89\n",
            "332\n",
            "380\n",
            "370\n",
            "178\n",
            "379\n",
            "245\n",
            "209\n",
            "235\n",
            "78\n",
            "300\n",
            "60\n",
            "285\n",
            "151\n",
            "218\n",
            "333\n",
            "104\n",
            "307\n",
            "124\n",
            "344\n",
            "324\n",
            "27\n",
            "119\n",
            "385\n",
            "355\n",
            "390\n",
            "44\n",
            "195\n",
            "125\n",
            "131\n",
            "239\n",
            "159\n",
            "257\n",
            "31\n",
            "398\n",
            "227\n",
            "343\n",
            "43\n",
            "17\n",
            "187\n",
            "160\n",
            "262\n",
            "345\n",
            "74\n",
            "12\n",
            "189\n",
            "397\n",
            "381\n",
            "315\n",
            "377\n",
            "303\n",
            "114\n",
            "353\n",
            "206\n",
            "123\n",
            "291\n",
            "73\n",
            "150\n",
            "258\n",
            "135\n",
            "265\n",
            "156\n",
            "246\n",
            "199\n",
            "269\n",
            "196\n",
            "316\n",
            "288\n",
            "357\n",
            "328\n",
            "126\n",
            "162\n",
            "7\n",
            "329\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.read_csv('drive/MyDrive/CASAS400/diagnosis_types.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "LrPRWkGrgECw",
        "outputId": "f090635f-383f-4ad8-ac06-52edadcb4d7c"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   diagnosis_id                             description\n",
              "0             1                                dementia\n",
              "1             2                                     MCI\n",
              "2             3                        middle age 45-59\n",
              "3             4                         young-old 60-74\n",
              "4             5                             old-old 75+\n",
              "5             6                           other medical\n",
              "6             7   watch/at risk - follow longitudinally\n",
              "7             8                           younger adult\n",
              "8             9  younger adult, English second language\n",
              "9            10                 diagnosis not available"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2d06e2a3-aa9f-422a-a4cd-3b1f0b4d9d53\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>diagnosis_id</th>\n",
              "      <th>description</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>dementia</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>MCI</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>middle age 45-59</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>young-old 60-74</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>old-old 75+</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>other medical</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7</td>\n",
              "      <td>watch/at risk - follow longitudinally</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8</td>\n",
              "      <td>younger adult</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>9</td>\n",
              "      <td>younger adult, English second language</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>10</td>\n",
              "      <td>diagnosis not available</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2d06e2a3-aa9f-422a-a4cd-3b1f0b4d9d53')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2d06e2a3-aa9f-422a-a4cd-3b1f0b4d9d53 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2d06e2a3-aa9f-422a-a4cd-3b1f0b4d9d53');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv\n",
        "\n",
        "class GCN(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = GCNConv(dataset[0].x.shape[1], 16)\n",
        "        self.conv2 = GCNConv(16, 10)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        x = self.conv2(x, edge_index)\n",
        "\n",
        "        return F.log_softmax(x, dim=1)\n",
        "\n",
        "model = GCN()\n",
        "print(model)\n",
        "print(\"Number of parameters: \", sum(p.numel() for p in model.parameters()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KqHmbau0mMEy",
        "outputId": "298cd3ff-3d06-4f0a-fad8-4777487fc2f7"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GCN(\n",
            "  (conv1): GCNConv(74, 16)\n",
            "  (conv2): GCNConv(16, 10)\n",
            ")\n",
            "Number of parameters:  1370\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_size = 64\n",
        "\n",
        "class GCN(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        # Init parent\n",
        "        super(GCN, self).__init__()\n",
        "        torch.manual_seed(42)\n",
        "\n",
        "        # GCN layers\n",
        "        self.initial_conv = GCNConv(dataset[0].x.shape[1], embedding_size)\n",
        "        self.conv1 = GCNConv(embedding_size, embedding_size)\n",
        "        self.conv2 = GCNConv(embedding_size, embedding_size)\n",
        "        self.conv3 = GCNConv(embedding_size, embedding_size)\n",
        "\n",
        "        # Output layer\n",
        "        self.out = Linear(embedding_size*2, 1)\n",
        "\n",
        "    def forward(self, x, edge_index, batch_index):\n",
        "        # First Conv layer\n",
        "        hidden = self.initial_conv(x, edge_index)\n",
        "        hidden = F.tanh(hidden)\n",
        "\n",
        "        # Other Conv layers\n",
        "        hidden = self.conv1(hidden, edge_index)\n",
        "        hidden = F.tanh(hidden)\n",
        "        hidden = self.conv2(hidden, edge_index)\n",
        "        hidden = F.tanh(hidden)\n",
        "        hidden = self.conv3(hidden, edge_index)\n",
        "        hidden = F.tanh(hidden)\n",
        "          \n",
        "        # Global Pooling (stack different aggregations)\n",
        "        hidden = torch.cat([gmp(hidden, batch_index), \n",
        "                            gap(hidden, batch_index)], dim=1)\n",
        "\n",
        "        # Apply a final (linear) classifier.\n",
        "        out = self.out(hidden)\n",
        "\n",
        "        return out, hidden\n",
        "\n",
        "model = GCN()\n",
        "print(model)\n",
        "print(\"Number of parameters: \", sum(p.numel() for p in model.parameters()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-QiABNoideRM",
        "outputId": "6f129e4d-b1b6-408d-eebe-3d8a1723e88e"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GCN(\n",
            "  (initial_conv): GCNConv(74, 64)\n",
            "  (conv1): GCNConv(64, 64)\n",
            "  (conv2): GCNConv(64, 64)\n",
            "  (conv3): GCNConv(64, 64)\n",
            "  (out): Linear(in_features=128, out_features=1, bias=True)\n",
            ")\n",
            "Number of parameters:  17409\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.data import DataLoader\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Root mean squared error\n",
        "loss_fn = torch.nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.0007)  \n",
        "\n",
        "# Use GPU for training\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "# Wrap data in a data loader\n",
        "data_size = len(dataset)\n",
        "NUM_GRAPHS_PER_BATCH = 64\n",
        "loader = DataLoader(dataset[:int(data_size * 0.8)], \n",
        "                    batch_size=NUM_GRAPHS_PER_BATCH, shuffle=True)\n",
        "test_loader = DataLoader(dataset[int(data_size * 0.8):], \n",
        "                         batch_size=NUM_GRAPHS_PER_BATCH, shuffle=True)\n",
        "\n",
        "def train(data):\n",
        "    # Enumerate over the data\n",
        "    for batch in loader:\n",
        "      # Use GPU\n",
        "      batch.to(device)  \n",
        "      # Reset gradients\n",
        "      optimizer.zero_grad() \n",
        "      # Passing the node features and the connection info\n",
        "      pred = model(batch) \n",
        "      # Calculating the loss and gradients\n",
        "      loss = torch.sqrt(loss_fn(pred, batch.y))       \n",
        "      loss.backward()  \n",
        "      # Update using the gradients\n",
        "      optimizer.step()   \n",
        "    return loss\n",
        "\n",
        "print(\"Starting training...\")\n",
        "losses = []\n",
        "for epoch in range(2000):\n",
        "    loss = train(dataset)\n",
        "    losses.append(loss)\n",
        "    if epoch % 100 == 0:\n",
        "      print(f\"Epoch {epoch} | Train Loss {loss}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "id": "LMcSmedJePAt",
        "outputId": "6ae1c681-2aec-4976-abd1-6f77aec836b3"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training...\n",
            "torch.Size([3582, 10])\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-108-6434fdcbd4af>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m     \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-108-6434fdcbd4af>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m     30\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m       \u001b[0;31m# Calculating the loss and gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m       \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m       \u001b[0;31m# Update using the gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mnll_loss\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   2530\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2531\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2532\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss_nd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2534\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Expected input batch_size (3582) to match target batch_size (64)."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os.path as osp\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import torch_geometric.transforms as T\n",
        "from torch_geometric.datasets import Planetoid\n",
        "from torch_geometric.nn import SplineConv\n",
        "\n",
        "data = dataset[0]\n",
        "\n",
        "\n",
        "class Net(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = SplineConv(dataset[0].x.shape[1], 16, dim=1, kernel_size=2)\n",
        "        self.conv2 = SplineConv(16, 10, dim=1, kernel_size=2)\n",
        "\n",
        "    def forward(self):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        x = F.elu(self.conv1(x, edge_index))\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return F.log_softmax(x, dim=1)\n",
        "\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model, data = Net().to(device), data.to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-3)\n",
        "\n",
        "\n",
        "def train():\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    F.nll_loss(model()[data.train_mask], data.y[data.train_mask]).backward()\n",
        "    optimizer.step()\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def test():\n",
        "    model.eval()\n",
        "    log_probs, accs = model(), []\n",
        "    for _, mask in data('train_mask', 'test_mask'):\n",
        "        pred = log_probs[mask].max(1)[1]\n",
        "        acc = pred.eq(data.y[mask]).sum().item() / mask.sum().item()\n",
        "        accs.append(acc)\n",
        "    return accs\n",
        "\n",
        "\n",
        "for epoch in range(1, 201):\n",
        "    train()\n",
        "    train_acc, test_acc = test()\n",
        "    print(f'Epoch: {epoch:03d}, Train: {train_acc:.4f}, Test: {test_acc:.4f}')"
      ],
      "metadata": {
        "id": "Y5MdfGiHfvuy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}